{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d93603c",
   "metadata": {},
   "source": [
    "# spaCy\n",
    "\n",
    "All-in-one package for performing basic and advanced natural language processing, with special optimization \"quickstart\" features for certain languages. See [spaCy Language Support](https://spacy.io/usage/models#languages) for details.\n",
    "\n",
    "## Features\n",
    "\n",
    "* **Tokenization**: Segmenting text into individual \"tokens\", that is, words, punctuations marks, numbers, etc.\n",
    "\n",
    "* **Part-of-speech (POS) Tagging**: Assigning grammatical word types to tokens, like \"verb\" or \"noun\" (using [Universal POS Tags](https://universaldependencies.org/u/pos/) with `.pos_` and [Penn Part of Speech Tags](https://cs.nyu.edu/~grishman/jet/guide/PennPOS.html) with `.tag_`).\n",
    "\n",
    "* **Dependency Parsing**: Assigning syntactic dependency labels, describing the relations between individual tokens, as in subject, object, dependent clause, etc.\n",
    "\n",
    "* **Lemmatization**: Determining the base form, or *lemma* of a word.  The lemma of \"went\" is \"to go\", and the lemma of \"trees\" is \"tree\".\n",
    "\n",
    "* **Named Entity Recognition (NER)**: Labeling \"real-world\" objects with names, such as persons, companies or locations.\n",
    "\n",
    "## Installing Pre-Trained Models\n",
    "\n",
    "```\n",
    "%run -m spacy download en_core_web_sm\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4c20b3",
   "metadata": {},
   "source": [
    "## Linguistic Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04b20ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5d5cd7c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wow INTJ UH\n",
      "! PUNCT .\n",
      "Oh INTJ UH\n",
      "no INTJ UH\n",
      ", PUNCT ,\n",
      "I PRON PRP\n",
      "forgot VERB VBD\n",
      "to PART TO\n",
      "buy VERB VB\n",
      "ten NUM CD\n",
      "oranges NOUN NNS\n",
      "and CCONJ CC\n",
      "seven NUM CD\n",
      "apples NOUN NNS\n",
      "for ADP IN\n",
      "the DET DT\n",
      "party NOUN NN\n",
      "tomorrow NOUN NN\n",
      ", PUNCT ,\n",
      "but CCONJ CC\n",
      "I PRON PRP\n",
      "promise VERB VBP\n",
      "I PRON PRP\n",
      "'ll VERB MD\n",
      "get VERB VB\n",
      "them PRON PRP\n",
      "soon ADV RB\n",
      ". PUNCT .\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"\"\"Wow! Oh no, I forgot to buy ten oranges and seven apples for the party tomorrow, but I promise I'll get them soon.\"\"\")\n",
    "for token in doc:\n",
    "    print(token, token.pos_, token.tag_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "53ec19ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wow --> wow\n",
      "! --> !\n",
      "Oh --> oh\n",
      "no --> no\n",
      ", --> ,\n",
      "I --> -PRON-\n",
      "forgot --> forget\n",
      "to --> to\n",
      "buy --> buy\n",
      "ten --> ten\n",
      "oranges --> orange\n",
      "and --> and\n",
      "seven --> seven\n",
      "apples --> apple\n",
      "for --> for\n",
      "the --> the\n",
      "party --> party\n",
      "tomorrow --> tomorrow\n",
      ", --> ,\n",
      "but --> but\n",
      "I --> -PRON-\n",
      "promise --> promise\n",
      "I --> -PRON-\n",
      "'ll --> will\n",
      "get --> get\n",
      "them --> -PRON-\n",
      "soon --> soon\n",
      ". --> .\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, \"-->\", token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2492c0c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Nellie, a cruising yawl, swung to her anchor without a flutter of the sails, and was at rest. The flood had made, the wind was nearly calm, and being bound down the river, the only thing for it was to come to and wait for the turn of the tide.\n",
      "The sea-reach of the Thames stretched before us like the beginning of an interminable waterway. In the offing the sea and the sky were welded together without a joint, and in the luminous space the tanned sails of the barges drifting up with the tide seemed to stand still in red clusters of canvas sharply peaked, with gleams of varnished sprits. A haze rested on the low shores that ran out to sea in vanishing flatness. The air was dark above Gravesend,\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/Victorian/Conrad_HeartofDarkness.txt\") as f:\n",
    "    text = nlp(f.read())\n",
    "print(text[:150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f0f8661e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Nellie, a cruising yawl, swung to her anchor without a flutter of the sails, and was at rest.\n"
     ]
    }
   ],
   "source": [
    "for sent in text.sents:\n",
    "    print(sent)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e57cff44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 The Nellie, a cruising yawl, swung to her anchor without a flutter of the sails, and was at rest.\n",
      "2 The flood had made, the wind was nearly calm, and being bound down the river, the only thing for it was to come to and wait for the turn of the tide.\n",
      "3 The sea-reach of the Thames stretched before us like the beginning of an interminable waterway.\n",
      "4 In the offing the sea and the sky were welded together without a joint, and in the luminous space the tanned sails of the barges drifting up with the tide seemed to stand still in red clusters of canvas sharply peaked, with gleams of varnished sprits.\n",
      "5 A haze rested on the low shores that ran out to sea in vanishing flatness.\n",
      "6 The air was dark above Gravesend, and farther back still seemed condensed into a mournful gloom, brooding motionless over the biggest, and the greatest, town on earth.\n",
      "7 The Director of Companies was our captain and our host.\n",
      "8 We four affectionately watched his back as he stood in the bows looking to seaward.\n",
      "9 On the whole river there was nothing that looked half so nautical.\n",
      "10 He resembled a pilot, which to a seaman is trustworthiness personified.\n"
     ]
    }
   ],
   "source": [
    "count = 1\n",
    "for sent in text.sents:\n",
    "    print(count, sent.text.strip())\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "00619d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_list = list(text.sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "46f069f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2700"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentence_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "092ea254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "How long would it last?"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_list[1350]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5ff339",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc1df07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
